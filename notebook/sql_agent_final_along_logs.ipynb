{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a03e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Annotated, Literal, TypedDict, List, Dict, Any, Optional\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import time  # For timing LLM calls\n",
    "# %%\n",
    "# === LOGGING SETUP (Console logging DISABLED - ALL LEVELS TO FILE) ===\n",
    "def get_logger(name: str) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Create and return a logger that saves ALL log levels to file only (no console output).\n",
    "    Captures DEBUG, INFO, WARNING, ERROR, CRITICAL - everything under control.\n",
    "    Avoids duplicate handlers.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)  # Capture everything from DEBUG and above\n",
    "    logger.propagate = False\n",
    "    if logger.handlers:\n",
    "        return logger  # Prevent adding handlers multiple times\n",
    "    # Create logs directory\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    # Daily log file\n",
    "    log_file = os.path.join(log_dir, f\"{datetime.now().strftime('%Y-%m-%d')}.log\")\n",
    "    # File handler only (NO console handler) - Set to DEBUG to capture ALL levels\n",
    "    fh = logging.FileHandler(log_file, encoding='utf-8')\n",
    "    fh.setLevel(logging.DEBUG)  # Ensure all levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) are written\n",
    "    # Enhanced formatter to clearly show all log levels\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s [%(levelname)-8s] %(name)s: %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    fh.setFormatter(formatter)\n",
    "    # Add handler\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "# %%\n",
    "# Initialize logger (silent to console, ALL levels to file)\n",
    "logger = get_logger(\"SQLAgent\")\n",
    "logger.info(\"=== SQL Agent Logger Initialized (Console Output Disabled, ALL Log Levels Captured) ===\")\n",
    "logger.debug(\"DEBUG level logging enabled - all detailed information will be captured\")\n",
    "logger.warning(\"WARNING level logging enabled - all warnings will be captured\")\n",
    "logger.error(\"ERROR level logging enabled - all errors will be captured\")\n",
    "logger.critical(\"CRITICAL level logging enabled - all critical issues will be captured\")\n",
    "# %%\n",
    "class State(TypedDict):\n",
    "    \"\"\"Represents the state of our graph.\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    query_attempts: int  # Track query attempts to prevent infinite loops\n",
    "    final_answer: Optional[str]  # Store the final answer\n",
    "# %%\n",
    "class SQLAgent:\n",
    "    \"\"\"SQL Agent that uses LangGraph to interact with a SQLite database.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_path: str,\n",
    "        model_name: str = \"llama-3.1-8b-instant\",\n",
    "        groq_api_key: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"Initialize the SQL Agent with a SQLite database connection and Groq LLM.\"\"\"\n",
    "        logger.info(\"Initializing SQLAgent...\")\n",
    "        logger.debug(f\"Input - db_path: {db_path}, model_name: {model_name}\")\n",
    "        # Create SQLite connection string\n",
    "        self.connection_string = f\"sqlite:///{db_path}\"\n",
    "        logger.debug(f\"Connection string created: {self.connection_string}\")\n",
    "        self.db = SQLDatabase.from_uri(self.connection_string)\n",
    "        logger.info(\"Connected to SQLite database.\")\n",
    "        logger.debug(f\"Database usable tables: {self.db.get_usable_table_names()}\")\n",
    "        # Initialize Groq LLM\n",
    "        self.llm = ChatGroq(\n",
    "            model=model_name,\n",
    "            api_key=groq_api_key or os.getenv(\"GROQ_API_KEY\"),\n",
    "            temperature=0,\n",
    "        )\n",
    "        logger.info(f\"Groq LLM initialized with model: {model_name}\")\n",
    "        # Setup components\n",
    "        self._setup_tools()\n",
    "        self._setup_prompts()\n",
    "        self._build_graph()\n",
    "        logger.info(\"SQLAgent initialization completed.\")\n",
    "\n",
    "    def _setup_tools(self) -> None:\n",
    "        \"\"\"Set up the required tools for database interaction.\"\"\"\n",
    "        logger.info(\"Starting _setup_tools...\")\n",
    "        toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)\n",
    "        tools = toolkit.get_tools()\n",
    "        logger.debug(f\"Fetched {len(tools)} tools from toolkit: {[t.name for t in tools]}\")\n",
    "        # Extract standard tools\n",
    "        self.list_tables_tool = next(\n",
    "            tool for tool in tools if tool.name == \"sql_db_list_tables\"\n",
    "        )\n",
    "        logger.debug(\"Tool 'sql_db_list_tables' loaded.\")\n",
    "        self.get_schema_tool = next(\n",
    "            tool for tool in tools if tool.name == \"sql_db_schema\"\n",
    "        )\n",
    "        logger.debug(\"Tool 'sql_db_schema' loaded.\")\n",
    "        # Define the query execution tool\n",
    "        @tool\n",
    "        def db_query_tool(query: str) -> str:\n",
    "            \"\"\"Execute a SQL query against the SQLite database and get back the result.\"\"\"\n",
    "            logger.info(f\"db_query_tool called with query: {query}\")\n",
    "            try:\n",
    "                result = self.db.run_no_throw(query)\n",
    "                if result is None or result == \"\" or result == []:\n",
    "                    logger.info(\"Query executed but returned no results.\")\n",
    "                    return \"Query executed successfully but returned no results.\"\n",
    "                logger.info(f\"Query result: {result}\")\n",
    "                return str(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in db_query_tool: {repr(e)}\")\n",
    "                return f\"Error: {str(e)}\"\n",
    "        self.db_query_tool = db_query_tool\n",
    "        logger.info(\"All tools setup completed.\")\n",
    "\n",
    "    def _setup_prompts(self) -> None:\n",
    "        \"\"\"Set up the system prompts for query generation and checking.\"\"\"\n",
    "        logger.info(\"Setting up prompts...\")\n",
    "        self.query_gen_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert SQLite database assistant. Your task is to generate SQL queries to answer user questions.\n",
    "                    IMPORTANT RULES:\n",
    "                    1. Generate ONLY valid SQLite SELECT queries\n",
    "                    2. Use proper SQLite syntax (no MySQL/PostgreSQL specific functions)\n",
    "                    3. Be careful with table and column names - use exact names from the schema\n",
    "                    4. When in doubt about column names, use SELECT * to see all columns first\n",
    "                    5. Use LIMIT to prevent huge result sets\n",
    "                    6. Return ONLY the SQL query, nothing else\n",
    "                    Example good responses:\n",
    "                    - SELECT * FROM employees LIMIT 10;\n",
    "                    - SELECT name, salary FROM employees WHERE department = 'IT';\n",
    "                    - SELECT COUNT(*) FROM orders;\"\"\",\n",
    "            ),\n",
    "            (\"placeholder\", \"{messages}\"),\n",
    "        ])\n",
    "        logger.debug(\"Query generation prompt created.\")\n",
    "        self.interpret_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a data analyst. Your job is to interpret SQL query results and provide clear answers.\n",
    "                    Given the query results, provide a clear, human-readable answer that directly addresses the user's question.\n",
    "                    Start your response with \"Answer: \" followed by your interpretation.\n",
    "                    If the results are empty, explain that no matching records were found.\n",
    "                    If there's an error, suggest what might be wrong and how to fix it.\"\"\",\n",
    "            ),\n",
    "            (\"placeholder\", \"{messages}\"),\n",
    "        ])\n",
    "        logger.debug(\"Interpretation prompt created.\")\n",
    "        logger.info(\"Prompts setup completed.\")\n",
    "\n",
    "        # === NEW: Intent Classification Prompt (Uses LLM to detect pure greetings) ===\n",
    "        self.intent_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                You are an intent classifier. Determine if the user's message is:\n",
    "                - A greeting only (e.g., 'hi', 'hello', 'good morning', 'how are you')\n",
    "                - OR a real question about data (e.g., asking for email, orders, users)\n",
    "\n",
    "                Respond ONLY with:\n",
    "                - \"greeting\" → if it's small talk with no request\n",
    "                - \"query\" → if there's any data request, even after a greeting\n",
    "\n",
    "                Examples:\n",
    "                User: Hi\n",
    "                AI: greeting\n",
    "\n",
    "                User: Hello, how are you?\n",
    "                AI: greeting\n",
    "\n",
    "                User: Hi, can you show me Arun Pandey's email?\n",
    "                AI: query\n",
    "\n",
    "                User: Good morning, what is my balance?\n",
    "                AI: query\n",
    "\n",
    "                User: Hey!\n",
    "                AI: greeting\n",
    "\n",
    "                User: Find all users named Arun\n",
    "                AI: query\n",
    "                \"\"\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        logger.debug(\"Intent classification prompt added.\")\n",
    "\n",
    "    def _create_tool_node_with_fallback(self, tools: list) -> RunnableWithFallbacks:\n",
    "        \"\"\"Create a tool node with error handling.\"\"\"\n",
    "        logger.debug(f\"Creating tool node with fallback for tools: {[t.name for t in tools]}\")\n",
    "        def handle_tool_error(state: Dict) -> Dict:\n",
    "            error = state.get(\"error\")\n",
    "            tool_calls = state.get(\"messages\", [])[-1].tool_calls if state.get(\"messages\") else []\n",
    "            logger.error(f\"Tool error caught: {repr(error)}\")\n",
    "            return {\n",
    "                \"messages\": [\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error: {repr(error)}\",\n",
    "                        tool_call_id=tc[\"id\"],\n",
    "                    )\n",
    "                    for tc in tool_calls\n",
    "                ]\n",
    "            }\n",
    "        result = ToolNode(tools).with_fallbacks(\n",
    "            [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "        )\n",
    "        logger.debug(\"Tool node with fallback created.\")\n",
    "        return result\n",
    "\n",
    "    def _build_graph(self) -> None:\n",
    "        \"\"\"Build the LangGraph workflow.\"\"\"\n",
    "        logger.info(\"Building LangGraph workflow...\")\n",
    "        workflow = StateGraph(State)\n",
    "\n",
    "        def first_tool_call(state: State) -> Dict:\n",
    "            \"\"\"Initial node to list database tables.\"\"\"\n",
    "            logger.info(\"Executing first_tool_call: requesting list of tables.\")\n",
    "            response = {\n",
    "                \"messages\": [\n",
    "                    AIMessage(\n",
    "                        content=\"\",\n",
    "                        tool_calls=[\n",
    "                            {\n",
    "                                \"name\": \"sql_db_list_tables\",\n",
    "                                \"args\": {},\n",
    "                                \"id\": \"tool_abcd123\",\n",
    "                            }\n",
    "                        ],\n",
    "                    )\n",
    "                ],\n",
    "                \"query_attempts\": 0,\n",
    "                \"final_answer\": None\n",
    "            }\n",
    "            logger.debug(\"first_tool_call response prepared.\")\n",
    "            return response\n",
    "\n",
    "        def model_get_schema(state: State) -> Dict:\n",
    "            \"\"\"Get database schema information.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            logger.info(\"Calling model_get_schema to fetch schema.\")\n",
    "            logger.debug(f\"Current message history: {[(type(m).__name__, m.content) for m in messages]}\")\n",
    "            chat_with_get_schema = self.llm.bind_tools([self.get_schema_tool])\n",
    "            start_time = time.time()\n",
    "            result = chat_with_get_schema.invoke(messages)\n",
    "            end_time = time.time()\n",
    "            llm_time = end_time - start_time\n",
    "            logger.info(f\"LLM schema request took {llm_time:.2f} seconds.\")\n",
    "            logger.debug(f\"Schema response: {result}\")\n",
    "            return {\"messages\": [result]}\n",
    "\n",
    "        def query_gen_node(state: State) -> Dict:\n",
    "            \"\"\"Generate SQL query based on user question and context.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            logger.info(\"Entering query_gen_node to generate SQL query.\")\n",
    "            logger.debug(f\"Message history: {[(type(m).__name__, m.content) for m in messages]}\")\n",
    "            # Increment query attempts\n",
    "            query_attempts = state.get(\"query_attempts\", 0) + 1\n",
    "            logger.debug(f\"Query attempt #{query_attempts}\")\n",
    "            # If we've tried too many times, give up\n",
    "            if query_attempts > 3:\n",
    "                logger.critical(\"CRITICAL: Max query attempts (3) exceeded. Unable to generate valid SQL query.\")\n",
    "                logger.warning(f\"WARNING: Query generation failed after {query_attempts} attempts for question: {messages[0].content if messages else 'Unknown'}\")\n",
    "                return {\n",
    "                    \"messages\": [AIMessage(content=\"Unable to generate a working query after multiple attempts.\")],\n",
    "                    \"query_attempts\": query_attempts,\n",
    "                    \"final_answer\": \"Unable to generate a working query after multiple attempts.\"\n",
    "                }\n",
    "            # Generate query using the prompt\n",
    "            logger.info(\"Invoking LLM for SQL generation...\")\n",
    "            start_time = time.time()\n",
    "            query_response = (self.query_gen_prompt | self.llm).invoke({\"messages\": messages})\n",
    "            end_time = time.time()\n",
    "            llm_time = end_time - start_time\n",
    "            logger.info(f\"LLM generated SQL in {llm_time:.2f} seconds.\")\n",
    "            logger.debug(f\"LLM response content: {query_response.content}\")\n",
    "            return {\n",
    "                \"messages\": [query_response],\n",
    "                \"query_attempts\": query_attempts\n",
    "            }\n",
    "\n",
    "        def execute_query_node(state: State) -> Dict:\n",
    "            \"\"\"Execute the SQL query.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            logger.info(\"Executing SQL query from last message.\")\n",
    "            logger.debug(f\"Last message type: {type(last_message).__name__}, content: {last_message.content}\")\n",
    "            # Extract SQL query from the last message\n",
    "            sql_query = last_message.content.strip()\n",
    "            logger.debug(f\"Raw SQL content: {sql_query}\")\n",
    "            # Clean up the query - look for SELECT statement\n",
    "            if \"SELECT\" in sql_query.upper():\n",
    "                lines = sql_query.split('\\n')\n",
    "                for line in lines:\n",
    "                    if 'SELECT' in line.upper():\n",
    "                        sql_query = line.strip()\n",
    "                        if sql_query.endswith('.'):\n",
    "                            sql_query = sql_query[:-1]\n",
    "                        break\n",
    "            logger.info(f\"Extracted SQL query: {sql_query}\")\n",
    "            # Execute the query\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                result = self.db.run_no_throw(sql_query)\n",
    "                end_time = time.time()\n",
    "                exec_time = end_time - start_time\n",
    "                logger.info(f\"Query executed in {exec_time:.2f} seconds.\")\n",
    "                if result is None or result == \"\" or result == []:\n",
    "                    content = \"Query executed successfully but returned no results.\"\n",
    "                    logger.info(\"Query returned no results.\")\n",
    "                else:\n",
    "                    content = str(result)\n",
    "                    logger.info(f\"Query result: {content[:200]}{'...' if len(str(result)) > 200 else ''}\")\n",
    "                return {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            content=content,\n",
    "                            tool_call_id=\"manual_query_execution\"\n",
    "                        )\n",
    "                    ]\n",
    "                }\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error executing query: {str(e)}\"\n",
    "                logger.error(error_msg)\n",
    "                return {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            content=error_msg,\n",
    "                            tool_call_id=\"manual_query_execution\"\n",
    "                        )\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "        def interpret_results_node(state: State) -> Dict:\n",
    "            \"\"\"Interpret the query results and provide final answer.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            logger.info(\"Interpreting query results into natural language answer.\")\n",
    "            logger.debug(f\"Message history for interpretation: {[(type(m).__name__, m.content) for m in messages]}\")\n",
    "            logger.info(\"Invoking LLM for result interpretation...\")\n",
    "            start_time = time.time()\n",
    "            interpretation = (self.interpret_prompt | self.llm).invoke({\"messages\": messages})\n",
    "            end_time = time.time()\n",
    "            llm_time = end_time - start_time\n",
    "            logger.info(f\"LLM interpretation completed in {llm_time:.2f} seconds.\")\n",
    "            logger.debug(f\"Interpretation result: {interpretation.content}\")\n",
    "            return {\n",
    "                \"messages\": [interpretation],\n",
    "                \"final_answer\": interpretation.content\n",
    "            }\n",
    "\n",
    "        def should_continue_after_query_gen(state: State) -> Literal[END, \"execute_query\"]:\n",
    "            \"\"\"Determine if we should execute the query or end.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            if not messages:\n",
    "                logger.debug(\"No messages in state. Ending.\")\n",
    "                return END\n",
    "            last_message = messages[-1]\n",
    "            query_attempts = state.get(\"query_attempts\", 0)\n",
    "            if query_attempts > 3:\n",
    "                logger.debug(\"Max attempts reached. Ending.\")\n",
    "                return END\n",
    "            if (hasattr(last_message, 'content') and\n",
    "                    last_message.content and\n",
    "                    'SELECT' in last_message.content.upper()):\n",
    "                logger.info(\"Valid SELECT query detected. Proceeding to execute_query.\")\n",
    "                return \"execute_query\"\n",
    "            logger.debug(\"No valid query found. Ending.\")\n",
    "            return END\n",
    "\n",
    "        def should_continue_after_execution(state: State) -> Literal[END, \"interpret_results\", \"query_gen\"]:\n",
    "            \"\"\"Determine what to do after query execution.\"\"\"\n",
    "            messages = state[\"messages\"]\n",
    "            if not messages:\n",
    "                logger.debug(\"No messages after execution. Ending.\")\n",
    "                return END\n",
    "            last_message = messages[-1]\n",
    "            if (isinstance(last_message, ToolMessage) and\n",
    "                    last_message.content.startswith(\"Error\")):\n",
    "                query_attempts = state.get(\"query_attempts\", 0)\n",
    "                if query_attempts >= 3:\n",
    "                    logger.warning(\"Error after max attempts. Ending.\")\n",
    "                    return END\n",
    "                logger.warning(\"Query execution error. Retrying with new query.\")\n",
    "                return \"query_gen\"\n",
    "            if isinstance(last_message, ToolMessage):\n",
    "                logger.info(\"Query executed successfully. Proceeding to interpretation.\")\n",
    "                return \"interpret_results\"\n",
    "            logger.debug(\"Unknown state after execution. Ending.\")\n",
    "            return END\n",
    "\n",
    "        def should_continue_after_interpretation(state: State) -> Literal[END]:\n",
    "            \"\"\"Always end after interpretation.\"\"\"\n",
    "            logger.info(\"Final answer generated. Ending workflow.\")\n",
    "            return END\n",
    "\n",
    "        # Add nodes to graph\n",
    "        workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "        logger.debug(\"Node 'first_tool_call' added to graph.\")\n",
    "        workflow.add_node(\n",
    "            \"list_tables_tool\",\n",
    "            self._create_tool_node_with_fallback([self.list_tables_tool]),\n",
    "        )\n",
    "        logger.debug(\"Node 'list_tables_tool' added to graph.\")\n",
    "        workflow.add_node(\"model_get_schema\", model_get_schema)\n",
    "        logger.debug(\"Node 'model_get_schema' added to graph.\")\n",
    "        workflow.add_node(\n",
    "            \"get_schema_tool\",\n",
    "            self._create_tool_node_with_fallback([self.get_schema_tool]),\n",
    "        )\n",
    "        logger.debug(\"Node 'get_schema_tool' added to graph.\")\n",
    "        workflow.add_node(\"query_gen\", query_gen_node)\n",
    "        logger.debug(\"Node 'query_gen' added to graph.\")\n",
    "        workflow.add_node(\"execute_query\", execute_query_node)\n",
    "        logger.debug(\"Node 'execute_query' added to graph.\")\n",
    "        workflow.add_node(\"interpret_results\", interpret_results_node)\n",
    "        logger.debug(\"Node 'interpret_results' added to graph.\")\n",
    "\n",
    "        # Add edges\n",
    "        workflow.add_edge(START, \"first_tool_call\")\n",
    "        logger.debug(\"Edge: START → first_tool_call\")\n",
    "        workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "        logger.debug(\"Edge: first_tool_call → list_tables_tool\")\n",
    "        workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "        logger.debug(\"Edge: list_tables_tool → model_get_schema\")\n",
    "        workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "        logger.debug(\"Edge: model_get_schema → get_schema_tool\")\n",
    "        workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "        logger.debug(\"Edge: get_schema_tool → query_gen\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"query_gen\",\n",
    "            should_continue_after_query_gen,\n",
    "        )\n",
    "        logger.debug(\"Conditional edges added from 'query_gen'\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"execute_query\",\n",
    "            should_continue_after_execution,\n",
    "        )\n",
    "        logger.debug(\"Conditional edges added from 'execute_query'\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"interpret_results\",\n",
    "            should_continue_after_interpretation,\n",
    "        )\n",
    "        logger.debug(\"Conditional edges added from 'interpret_results'\")\n",
    "\n",
    "        # Compile the workflow with recursion limit\n",
    "        self.app = workflow.compile()\n",
    "        logger.info(\"LangGraph workflow compiled successfully.\")\n",
    "\n",
    "    def query(self, question: str, recursion_limit: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a query against the database using the agent.\"\"\"\n",
    "        logger.info(f\"Received query: '{question}'\")\n",
    "\n",
    "        # === USE LLM TO CHECK IF IT'S A PURE GREETING ===\n",
    "        try:\n",
    "            intent_chain = self.intent_prompt | self.llm\n",
    "            intent_response = intent_chain.invoke({\"input\": question})\n",
    "            intent = intent_response.content.strip().lower()\n",
    "            logger.info(f\"Intent classification result: '{intent}'\")\n",
    "            if intent == \"greeting\":\n",
    "                logger.info(\"Pure greeting detected via LLM. Responding directly.\")\n",
    "                return {\n",
    "                    \"sql_query\": None,\n",
    "                    \"answer\": \"Hello! How can I assist you today?\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to classify intent using LLM: {e}. Proceeding as query.\")\n",
    "        # === END OF GREETING CHECK ===\n",
    "\n",
    "        logger.info(f\"Setting recursion limit: {recursion_limit}\")\n",
    "        try:\n",
    "            # Invoke with recursion limit\n",
    "            config = {\"recursion_limit\": recursion_limit}\n",
    "            logger.info(\"Invoking agent workflow...\")\n",
    "            start_time = time.time()\n",
    "            messages = self.app.invoke(\n",
    "                {\"messages\": [HumanMessage(content=question)], \"query_attempts\": 0, \"final_answer\": None},\n",
    "                config=config\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            total_time = end_time - start_time\n",
    "            logger.info(f\"Agent workflow completed in {total_time:.2f} seconds.\")\n",
    "            # Extract results\n",
    "            final_sql_query = self._extract_final_sql_query(messages)\n",
    "            final_answer = messages.get(\"final_answer\")\n",
    "            if not final_answer:\n",
    "                last_message = messages[\"messages\"][-1] if messages[\"messages\"] else None\n",
    "                if last_message and hasattr(last_message, 'content'):\n",
    "                    final_answer = last_message.content\n",
    "                    logger.debug(\"Final answer extracted from last message.\")\n",
    "            logger.info(f\"Final SQL Query: {final_sql_query}\")\n",
    "            logger.info(f\"Final Answer: {final_answer}\")\n",
    "            return {\n",
    "                \"sql_query\": final_sql_query,\n",
    "                \"answer\": final_answer\n",
    "            }\n",
    "        except GraphRecursionError:\n",
    "            error_msg = \"Unable to process the query due to recursion limit. The query may be too complex or the database structure unclear.\"\n",
    "            logger.critical(f\"CRITICAL: GraphRecursionError occurred - {error_msg}\")\n",
    "            # Provide a more user-friendly error message\n",
    "            return {\n",
    "                \"sql_query\": None,\n",
    "                \"answer\": (\n",
    "                    \"Sorry, I couldn't process your request. \"\n",
    "                    \"Please make sure your question is about retrieving data (e.g., SELECT queries). \"\n",
    "                    \"If you asked to modify or drop tables, those actions are not allowed for safety reasons.\"\n",
    "                ),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            error_msg = (\n",
    "                \"Sorry, something went wrong while processing your request. \"\n",
    "                \"Please try again or rephrase your question.\"\n",
    "            )\n",
    "            logger.critical(f\"CRITICAL: Unexpected exception in query execution - {str(e)}\")\n",
    "            return {\n",
    "                \"sql_query\": None,\n",
    "                \"answer\": error_msg,\n",
    "            }\n",
    "\n",
    "    def _extract_final_sql_query(self, messages: Dict) -> Optional[str]:\n",
    "        \"\"\"Extract the final SQL query from the message history.\"\"\"\n",
    "        logger.debug(\"Extracting final SQL query from message history.\")\n",
    "        for msg in reversed(messages.get(\"messages\", [])):\n",
    "            if hasattr(msg, \"content\") and msg.content:\n",
    "                content = msg.content\n",
    "                if 'SELECT' in content.upper():\n",
    "                    lines = content.split('\\n')\n",
    "                    for line in lines:\n",
    "                        if 'SELECT' in line.upper():\n",
    "                            query = line.strip()\n",
    "                            if query.endswith('.'):\n",
    "                                query = query[:-1]\n",
    "                            logger.debug(f\"Extracted SQL query: {query}\")\n",
    "                            return query\n",
    "        logger.debug(\"No SQL query found in message history.\")\n",
    "        return None\n",
    "\n",
    "    def get_table_info(self) -> str:\n",
    "        \"\"\"Get information about all tables in the database.\"\"\"\n",
    "        logger.info(\"get_table_info called.\")\n",
    "        try:\n",
    "            result = self.db.get_table_info()\n",
    "            logger.debug(f\"Table info retrieved: {result[:300]}...\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error getting table information: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return error_msg\n",
    "\n",
    "    def list_tables(self) -> List[str]:\n",
    "        \"\"\"Get list of all table names in the database.\"\"\"\n",
    "        logger.info(\"list_tables called.\")\n",
    "        try:\n",
    "            tables = self.db.get_usable_table_names()\n",
    "            logger.debug(f\"Tables found: {tables}\")\n",
    "            return tables\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return [error_msg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83d48029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query: SELECT email FROM users WHERE name = 'Arun Pandey';\n",
      "Question: hi whats upp show me the email of Arun Pandey user?\n",
      "Answer: The email of Arun Pandey is arun@example.com.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"=== Starting SQL Agent  ===\")\n",
    "    # Initialize the SQL Agent with SQLite database\n",
    "    agent = SQLAgent(\n",
    "        db_path=r\"D:\\ML(ExtraClass Project)\\AGENT AI\\SQL-Sage-Intelligent-DB-Agent-with-Gemini-LangGraph\\database\\final_ecommerce.db\",\n",
    "        model_name=\"llama-3.1-8b-instant\",\n",
    "    )\n",
    "    logger.info(\"SQLAgent instance created.\")\n",
    "    # Execute example query (results already logged by the query method)\n",
    "    logger.info(\"=== Query Execution ===\")\n",
    "    question = \"hi whats upp show me the email of Arun Pandey user?\"\n",
    "    result = agent.query(question, recursion_limit=15)\n",
    "    print(\"SQL Query:\", result[\"sql_query\"])\n",
    "    print(\"Question:\", question)\n",
    "    print( result[\"answer\"])\n",
    "    logger.info(\"===  Query Execution Completed ===\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00083e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sqlagentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
